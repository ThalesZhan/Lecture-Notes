\chapter{Continuous Time Martingale}

\section{Filtration}

\begin{defn}[Filtration]
    A filtration is a family of increasing $\sigma$-fields $\mathbb{F} = (\mathcal{F}_t)_{t \geq 0}$ and let $\mathcal{F}_\infty = \bigcup_{t}\mathcal{F}_t$.
\end{defn}

\begin{exam}
    For a process $X = (X_t)_{t \geq 0}$, let $\mathcal{F}^X_t = \sigma(X_s \colon s \leq t)$. Then $(\mathcal{F}^X_t)_{t \geq 0}$ is a filtration, called the natural filtration of $X$.
\end{exam}

\begin{defn}[Right Continuity]
    Given a filtration $\mathbb{F} = (\mathcal{F}_t)_{t \geq 0}$. For any $t \geq 0$, define
    \begin{equation*}
        \mathcal{F}_{t+} \defeq \bigcap_{s > t} \mathcal{F}_s
    \end{equation*}
    and $\mathcal{F}_{\infty +} = \mathcal{F}_\infty$. In general, $\mathcal{F}_t \subset \mathcal{F}_{t+}$. If for any $t \geq 0$,
    \begin{equation*}
        \mathcal{F}_t = \mathcal{F}_{t+},
    \end{equation*}
    then the filtration is called right-continuous.
\end{defn}


\begin{defn}[Completeness]
    Given a filtration $\mathbb{F} = (\mathcal{F}_t)_{t \geq 0}$. Let
    \begin{equation*}
        N = \bb{A \colon \exists~A^\prime \supset A,~A^\prime \in \mathcal{F}_\infty,~\Pb(A^\prime) = 0}.
    \end{equation*}
    If $N \subset \mathcal{F}_0$, then the filtration is called complete.
\end{defn}
\begin{rmk}
    If a filtration is not complete, then define
    \begin{equation*}
        \mathcal{F}^\prime_t = \mathcal{F}_t \vee \sigma(N),
    \end{equation*}
    the smallest $\sigma$-field containing $\mathcal{F}_t$ and $\sigma(N)$. Then the filtration $(\mathcal{F}^\prime_t)_{t \geq 0}$ is complete. So in the following, we always consider complete filtration.
\end{rmk}
\begin{rmk}
    A filtration $\mathbb{F}$ is said to satisfy the usual condition if $\mathbb{F}$ is right-continuous and complete.
\end{rmk}

\noindent Given a stochastic process $X = (X_t)_{t \geq 0}$, note that 
\begin{equation*}
    X \colon \Omega \times [0,\infty) \sto \R
\end{equation*}
viewed by $X(\omega,t) = X_t(\omega)$. On $\Omega \times [0,\infty)$, we can consider the product $\sigma$-field $\mathcal{F} \times \mathcal{B}([0,\infty)$.
\begin{defn}[Measurability]
    Given a stochastic process $X = (X_t)_{t \geq 0}$.
    \begin{enumerate}[label=(\arabic{*})]
        \item $X$ is said to be measurable if $X(\omega,t)$ is $\mathcal{R} \times \mathcal{F}$-measurable.
        \item $X$ is said to be $(\mathcal{F}_t)_{t \geq 0}$-progressively measurable if for every $t$, $X \colon \Omega \times [0,t] \sto \R$ is  $\mathcal{F}_t \times \mathcal{B}([0,t])$-measurable.
        \item $X$ is called $(\mathcal{F}_t)_{t \geq 0}$-adapted if $X_t$ is $\mathcal{F}_t$-measurable for all $t$.
    \end{enumerate}
\end{defn}
\begin{rmk}
   Note that if $f \colon E_1 \times E_2 \sto \R$ is measurable, then for any $x\in E_1$, $f(x,\cdot) \colon E_2 \sto \R$ is also measurable. So if $X$ is progressively measurable, then it is adapted. Moreover, it is also measurable. Conversely, if $X$ is measurable and adapted, then it has a progressively measurable modification. 
\end{rmk}

\begin{prop}
    Suppose a stochastic process $X = (X_t)_{t \geq 0}$ is $\mathbb{F} = (\mathcal{F}_t)_{t \geq 0}$-adapted and $t \mapsto X_t(\omega)$ is right-continuous (or left-continuous) a.e.. Then $X$ is $\mathbb{F} = (\mathcal{F}_t)_{t \geq 0}$-progressively measurable.
\end{prop}
\begin{proof}
    Fix $t > 0$. Consider the process $X$ on $\Omega \times [0,t]$. Define for $s < t$
    \begin{equation*}
        X^n_s \defeq X_{\frac{kt}{n}},\quad\text{if } s \in \left[\frac{(k-1)t}{n},\frac{kt}{n}\right)
    \end{equation*}
    and $X^n_t = X_t$. Then by the right-continuity, $X^n_s \sto X_s$ a.e. (Similar for the left-continuity by taking the left-end point). Now for $A \in \mathcal{R}$,
    \begin{equation*}
        \bb{(\omega,s)\colon X^n_s(\omega) \in A} = \bc{\bb{X_t \in A}\times \bb{t}} \cup \bigcup_{k=1}^n\bc{\bb{X_{\frac{kt}{n}} \in A} \times \left[\frac{(k-1)t}{n},\frac{kt}{n}\right)} \in \mathcal{F}_t \times \mathcal{B}([0,t]),
    \end{equation*}
    because $X$ is adapted. So $X^n = (X^n_t)_{t\geq 0}$ is progressively measurable. By taking limits, $X$ is progressively measurable.
\end{proof}
\begin{rmk}
    A $\sigma$-field on $\Omega \times [0,\infty)$ is generated by all $(\mathcal{F}_t)_{t \geq 0}$-progressively measurable process, called $(\mathcal{F}_t)_{t \geq 0}$-progressively measurable $\sigma$-field.
\end{rmk}

\section{Stopping Time}

Fix a filtration $\mathbb{F} = (\mathcal{F}_t)_{t \geq 0}$.

\begin{defn}[Stopping Time]
    A random variable $T \colon \Omega \sto [0,\infty]$ is called a stopping time w.s.t. $(\mathcal{F}_t)_{t \geq 0}$ if $\bb{T \leq t} \in \mathcal{F}_t$ for all $t$.
\end{defn}
\begin{rmk}
    As mentioned before, $\bb{T < t} \in \mathcal{F}_t$ and so $\bb{T \geq t} \in \mathcal{F}_t$. Note that the converse is not true.
\end{rmk}

\begin{defn}
    Given a stopping time $T$, let
    \begin{equation*}
        \mathcal{F}_T \defeq \bb{A \in \mathcal{F}_\infty \colon \forall~t \geq 0,~ A \cap \bb{T \leq t} \in \mathcal{F}_t}.
    \end{equation*}
\end{defn}

\noindent Let $\mathcal{G}_t = \mathcal{F}_{t+}$ that is also a filtration and $\mathcal{G}_{t+} = \mathcal{G}_t$.
\begin{prop}
    \begin{enumerate}[label=(\arabic{*})]
        \item $T$ is a stopping time w.s.t. $(G_t)_{t \geq 0}$ if and only if for any $t > 0$,
        \begin{equation*}
             \bb{T < t} \subset \mathcal{F}_t,
        \end{equation*}
        which is also equivalent to $T \wedge t$ is $\mathcal{F}_t$-measurable.
        \item Let $T$ be a $(G_t)_{t \geq 0}$-stopping time. Then
        \begin{equation*}
            \mathcal{G}_T = \bb{A \in \mathcal{F}_\infty \colon \forall~t > 0,~A \cap \bb{T < t} \in \mathcal{F}_t}
        \end{equation*}
        In some way, $ \mathcal{F}_{T+} \defeq \mathcal{G}_T$.
    \end{enumerate} 
\end{prop}
\begin{proof}
    \begin{enumerate}[label=(\arabic{*})]
        \item Assume $T$ is a stopping time w.s.t. $(G_t)_{t \geq 0}$.
        \begin{equation*}
            \bb{T < t} = \bigcup_{q \in \Q,q < t} \bb{T \leq q}.
        \end{equation*}
        Because
        \begin{equation*}
            \bb{T \leq q} \in \mathcal{G}_q = \mathcal{F}_{q+} \subset \mathcal{F}_t,
        \end{equation*}
        $\bb{T < t} \in \mathcal{F}_t$.

        \noindent Conversely, for any $t \geq 0$ and any $s > t$,
        \begin{equation*}
            \bb{T \leq t} = \bigcap_{q \in \Q, t < q < s} \bb{T < q} \in \mathcal{F}_s,
        \end{equation*}
        because
        \begin{equation*}
            \bb{T < q} \in \mathcal{F}_q \subset \mathcal{F}_s.
        \end{equation*}
        So
        \begin{equation*}
            \bb{T \leq t} \in \bigcap_{s > t}\mathcal{F}_s = \mathcal{G}_t.
        \end{equation*}

        \item Let $A \in \mathcal{G}_T$. Then for all $t > 0$,
        \begin{equation*}
            A \cap \bb{T \leq t} \in \mathcal{G}_t.
        \end{equation*}
        Hence
        \begin{equation*}
            A \cap \bb{T < t} = \bigcup_{q \in \Q,q < t} A \cap \bb{T \leq q} \in \mathcal{F}_t.
        \end{equation*}
        Conversely, for any $A \in \mathcal{F}_\infty$ with $A \cap \bb{T < t} \in \mathcal{F}_t$ for all $t > 0$,
        \begin{equation*}
            A \cap \bb{T \leq t} = \bigcap_{q \in \Q, t < q < s} A \cap \bb{T < q} \in \mathcal{F}_s.
        \end{equation*} 
        So
        \begin{equation*}
            A \cap \bb{T \leq t} \in \bigcap_{s > t}\mathcal{F}_s = \mathcal{G}_t. \qedhere
        \end{equation*}
    \end{enumerate}
\end{proof}

\begin{prop}
    \begin{enumerate}[label=(\arabic{*})]
        \item For any stopping time $T$,
        \begin{equation*}
            \mathcal{F}_T \subset \mathcal{G}_T = \mathcal{F}_{T+}
        \end{equation*}

        \item If $T = t$, $\mathcal{F}_T = \mathcal{F}_t$.

        \item $T$ is $\mathcal{F}_T$-measurable.
    \end{enumerate}
\end{prop}
\begin{proof}
    \begin{enumerate}[label=(\arabic{*})]
        \item It is because
        \begin{equation*}
             A \cap \bb{T < t} = \bigcup_{q \in \Q,q < t} A \cap \bb{T \leq q}.
        \end{equation*}

        \item It is because
        \begin{equation*}
            A \cap \bb{T \leq s} = A \text{ or } \emptyset.
        \end{equation*}

        \item For any $a > 0$, let $A = \bb{T > a}$.
        \begin{align*}
            A \cap \bb{T \leq t} &= \bb{T > a} \cap \bb{T \leq t} \\
            &= \begin{cases}
                \emptyset,& a \geq t \\
                \bb{a < T \leq t},&a<t.
            \end{cases}
        \end{align*}
        Because
        \begin{equation*}
            \bb{a < T \leq t} = \bb{T \leq a}^c \cap \bb{T \leq t} \in \mathcal{F}_a \cap \mathcal{F}_t \subset \mathcal{F}_t,
        \end{equation*}
        $A \cap \bb{T \leq t} \in \mathcal{F}_t$.  \qedhere
    \end{enumerate}
\end{proof}


\begin{prop}
    \begin{enumerate}[label=(\arabic{*})]
        \item Let $T$ be a stopping time and $A \in \mathcal{F}_\infty$. Define
        \begin{equation*}
            T^A(\omega) \defeq \begin{cases}
                T(\omega),&\omega \in A, \\
                \infty,&\omega \notin A.
            \end{cases}
        \end{equation*}
        Then $T^A$ is a stopping time if and only if $A \in \mathcal{F}_T$.

        \item If $T$ is a stopping time, then $T + s$ is a stopping time for any constant $s \geq 0$.

        \item \label{item:3_stoptime} Let $S,T$ be stopping times with $S \leq T$. Then
        \begin{equation*}
            \mathcal{F}_S \subset \mathcal{F}_T,\quad \mathcal{F}_{S+} \subset \mathcal{F}_{T+}.
        \end{equation*}

        \item Let $S,T$ be stopping times. Then $S \vee T$ and $S \wedge T$ are stopping times. Moreover, $\mathcal{F}_{S \wedge T} = \mathcal{F}_S \cap \mathcal{F}_T$ and
        \begin{equation*}
            \bb{S \leq T} \in \mathcal{F}_{S \wedge T}.
        \end{equation*}
        So $\bb{T \leq S} \in \mathcal{F}_{S \wedge T}$ and $\bb{S = T} \in \mathcal{F}_{S \wedge T}$.
    \end{enumerate}
\end{prop}
\begin{proof}
    \begin{enumerate}[label=(\arabic{*})]
        \item Note that for any $t$,
        \begin{equation*}
            \bb{T^A \leq t} = A \cap \bb{T \leq t} \in \mathcal{F}_t.
        \end{equation*}

        \item It is because
        \begin{equation*}
            \bb{T + s \leq t} = \bb{T \leq t - s} \in \mathcal{F}_{t - s} \subset \mathcal{F}_t.
        \end{equation*}

        \item Note that $\bb{T \leq t} \subset \bb{S \leq t}$. For any $A \in \mathcal{F}_S$,
        \begin{equation*}
            A \cap \bb{T \leq t} = \bc{A \cap \bb{S \leq t}} \cap \bb{T \leq t} \in \mathcal{F}_t,
        \end{equation*}
        and similarly for $\mathcal{F}_{S+} \subset \mathcal{F}_{T+}$.

        \item Note that
        \begin{equation*}
            \bb{S \vee T \leq t} = \bb{S \leq t} \cap \bb{T \leq t} \in \mathcal{F}_t.
        \end{equation*}
        Similarly,
        \begin{equation*}
            \bb{S \wedge T \leq t} = \bb{S \leq t} \cup \bb{T \leq t} \in \mathcal{F}_t.
        \end{equation*}
        
        \noindent By \ref{item:3_stoptime}, 
        \begin{equation*}
            \mathcal{F}_{S \wedge T} \subset \mathcal{F}_S \cap \mathcal{F}_T.
        \end{equation*}
        Conversely, let $A \in \mathcal{F}_S \cap \mathcal{F}_T$. Then
        \begin{equation*}
            A \cap \bb{S \wedge T \leq t} = (A \cap \bb{S \leq t}) \cup (A \cap \bb{T \leq t}) \in \mathcal{F}_t.
        \end{equation*}
        So $\mathcal{F}_S \cap \mathcal{F}_T \subset \mathcal{F}_{S \wedge T}$.

        \noindent For any $t > 0$,
        \begin{equation*}
            \bb{S \leq T} \cap \bb{S \wedge T \leq t} = \bc{\bb{S \leq T} \cap\bb{S \leq t}} \cup \bc{\bb{S \leq T} \cap\bb{T \leq t}}.
        \end{equation*}
        Because
        \begin{equation*}
            \bb{S \leq T} \cap \bb{T \leq t} = \bb{S \leq t} \cap \bb{T \leq t} \cap \bb{S \wedge t \leq T \wedge t} 
        \end{equation*}
        and note that $S \wedge t,T \wedge t$ are $\mathcal{F}_t$-measurable,
        \begin{equation*}
            \bb{S \leq T} \cap \bb{T \leq t} \in \mathcal{F}_t.
        \end{equation*}
        For the other term, similarly
        \begin{equation*}
            \bb{S \leq T} \cap \bb{S \leq t} = \bb{S \wedge t \leq T \wedge t}  \cap \bb{S \leq t} \in \mathcal{F}_t.
        \end{equation*}
        So
        \begin{equation*}
            \bb{S \leq T} \cap \bb{S \wedge T \leq t} \in \mathcal{F}_t. \qedhere
        \end{equation*}
    \end{enumerate}
\end{proof}
\begin{rmk}
    For stopping times $S \leq T$, it can define the stochastic interval
    \begin{equation*}
        (S,T] \defeq \bb{(t,\omega) \in [0,\infty] \times \Omega \colon S(\omega) < t \leq T(\omega)},
    \end{equation*}
    so is similarly $[S,T],(S,T)$.
\end{rmk}

\begin{prop}
    \begin{enumerate}[label=(\arabic{*})]
        \item If $\bb{S_n}_{n \geq 0}$ is an increasing stopping time and $S_n \sto S$, then $S$ is a stopping time.
        \item If $\bb{S_n}_{n \geq 0}$ is a decreasing stopping time and $S_n \sto S$, then $S$ is a $(\mathcal{F}_{t+})$-stopping time and
        \begin{equation*}
            \mathcal{F}_{S+} = \bigcap_{n} \mathcal{F}_{S_n+}.
        \end{equation*}
    \end{enumerate}
\end{prop}
\begin{proof}
    \begin{enumerate}[label=(\arabic{*})]
        \item Because $S_n \uparrow S$,
        \begin{equation*}
            \bb{S \leq t} = \bigcap_n \bb{S_n \leq t} \in \mathcal{F}_t.
        \end{equation*}
        So $S$ is a stopping time.

        \item Because $S_n \downarrow S$,
        \begin{equation*}
            \bb{S < t} = \bigcup_{n} \bb{S_n < t} \in \mathcal{F}_t,\text{ and }A \cap \bb{S < t} = \bigcup_{n} (A \cap \bb{S_n < t}).
        \end{equation*}
        So $S$ is a $(\mathcal{F}_{t+})$-stopping time and $\mathcal{F}_{S+} \supset \bigcap_{n} \mathcal{F}_{S_n+}$. For the other side,
        \begin{equation*}
            A \cap \bb{S_n < t} = A \cap \bb{S < t} \cap \bb{S_n < t} \in \mathcal{F}_t. \qedhere
        \end{equation*}
    \end{enumerate}
\end{proof}

\begin{prop}
    Let $T$ be a stopping time. A random variable $Y$ defined on $\bb{T <\infty}$ is $\mathcal{F}_T$-measurable if and only if for any $t \geq 0$, $Y|_{\bb{T \leq t}}$ is $\mathcal{F}_t$-measurable.
\end{prop}
\begin{proof}
    For any $A \in \mathcal{R}$,
    \begin{equation*}
        \bb{Y \in A} \cap \bb{T \leq t} = \bb{Y|_{\bb{T \leq t}} \in A}. \qedhere
    \end{equation*}
\end{proof}
\begin{rmk}
    If $X = (X_t)_{t \geq 0}$ is progressively measurable and $T$ is a stopping time, then $X_T\mathbb{I}_{\bb{T<\infty}}$ is $\mathcal{F}_T$-measurable.
\end{rmk}

\begin{prop}
    Let $T$ be a stopping time. 
    \begin{enumerate}[label=(\arabic{*})]
        \item Let $S$ be a $\mathcal{F}_T$-measurable random variable with values $[0,\infty]$ such that $S \geq T$. Then $S$ is also a stopping time.

        \item Define
        \begin{equation*}
            T_n (\omega) = \sum_{k=0}^\infty \frac{k+1}{2^n}\mathbb{I}_{\bb{\frac{k}{2^n} < T(\omega) \leq \frac{k+1}{2^n}}} + \infty \mathbb{I}_{\bb{T(\omega) = \infty}}.
        \end{equation*}
        Then $T_n$ is a sequence of stopping times that decreases to $T$.
    \end{enumerate}
\end{prop}
\begin{proof}
    \begin{enumerate}[label=(\arabic{*})]
        \item For any $t \geq 0$, because $T \leq S$,
        \begin{equation*}
            \bb{S \leq t} = \bb{S \leq t} \cap \bb{T \leq t} \in \mathcal{F}_t.
        \end{equation*}

        \item Note that $T_n \geq T$ is $\mathcal{F}_T$-measurable so by $(1)$ it is a stopping time.
    \end{enumerate}
\end{proof}


\begin{exam}
    Let $(X_t)_{t \geq 0}$ be an adapted stochastic process. 
    \begin{enumerate}[label=(\arabic{*})]
        \item Assume $t \mapsto X_t(\omega)$ is right-continuous. Let $O$ be a open set.
        \begin{equation*}
            T_O \defeq \inf \bb{t \geq 0 \colon X_t \in O}
        \end{equation*}
        is a stopping time with respect to $(\mathcal{F}_{t+})_{t \geq 0}$.

        \item Assume $t \mapsto X_t(\omega)$ is continuous. Let $F$ be a closed set.
        \begin{equation*}
            T_F = \inf \bb{t \geq 0 \colon X_t \in F}
        \end{equation*}
        is a stopping time (w.s.t. $(\mathcal{F}_t)$).
    \end{enumerate}
    \begin{proof}
        \begin{enumerate}[label=(\arabic{*})]
            \item For any $t \geq 0$,
            \begin{equation*}
                \bb{T_O < t} = \bigcup_{q \in[0,t)\cap \Q} \bb{X_q \in O}.
            \end{equation*}
            To prove that, first, for any $\omega$ such that $T_O(\omega) = \alpha = \inf\bb{t \colon X_t(\omega) \in O} < t$, we can choose a rational sequence $t > t_n \downarrow \alpha$. By the right continuity of $X_t$, $X_{t_n}(\omega) \sto X_\alpha(\omega) \in O$. Because $O$ is open, there is a large $n$ such that $X_{t_n}(\omega) \in O$. So $\bb{T_O < t} \subset \bigcup_{q \in[0,t)\cap \Q} \bb{X_q \in O}$. The converse is obvious.

            \noindent So it directly has
            \begin{equation*}
                \bb{T_O < t} = \bigcup_{q \in[0,t)\cap \Q} \bb{X_q \in O} \in \mathcal{F}_t.
            \end{equation*}

            \item For any $t \geq 0$,
            \begin{equation*}
                \bb{T_F \leq t} = \bb{\inf_{0 \leq s \leq t} d(X_s,F) = 0}.
            \end{equation*}
            First, ``$\subset$'' is obvious. Conversely, there is a $\bb{t_n} \subset [0,t]$ such that $t_n \sto t_0 \leq t$ and
            \begin{equation*}
                \lim_n d(X_{t_n}(\omega),F) = d(\lim_nX_{t_n}(\omega),F) = d(X_{t_0}(\omega),F) = 0
            \end{equation*}
            because of the continuity. Since $F$ is closed, $X_{t_0}(\omega) \in F$ so $T_F(\omega) \leq t$.

            \noindent Then
            \begin{equation*}
                \bb{T_F \leq t} = \bb{\inf_{0 \leq s \leq t} d(X_s,F) = 0} =\bb{\inf_{s \in [0,t]\cap\Q} d(X_s,F) = 0} \in \mathcal{F}_t. \qedhere
            \end{equation*}
        \end{enumerate}
    \end{proof}
\end{exam}

\section{Martingale}

Fix a filtration $(\mathcal{F}_t)_{t \geq 0}$.

\begin{defn}
    A stochastic process $(X_t)_{t \geq 0}$ is called a submartingale if
    \begin{enumerate}[label=(\arabic{*})]
        \item $X_t \in L^1$ and $(X_t)_{t \geq 0}$ is adapted,
        \item for any $s < t$,
        \begin{equation*}
            \E[X_t \mid \mathcal{F}_s] \geq X_s.
        \end{equation*}
    \end{enumerate}
    If $\leq$ in $(2)$, it is called a supermartingale. If $(X_t)_{t \geq 0}$ is a sub and super martingale, it is called a martingale.
\end{defn}

\begin{exam}
    Let $(B_t)_{t \geq 0}$ be a Brownian motion and $(\mathcal{F}_t)_{t \geq 0}$ be the natural filtration.
    \begin{enumerate}[label=(\arabic{*})]
        \item $(B_t)_{t \geq 0}$ is a martingale.
        \item Let
        \begin{equation*}
            Y_t = B_t^2 - t.
        \end{equation*}
        Then $(Y_t)_{t \geq 0}$ is a martingale.
        \item Let.
        \begin{equation*}
            Z_t = \exp\bc{\theta B_t - \frac{1}{2}\theta^2 t}
        \end{equation*}
        Then $(Z_t)_{t \geq 0}$ is also a martingale.
    \end{enumerate}
    \begin{proof}
        \begin{enumerate}[label=(\arabic{*})]
            \item For any $s < t$,
            \begin{align*}
                \E[B_t \mid \mathcal{F}_s] &= \E[B_t - B_s \mid \mathcal{F}_s] + \E[B_s \mid \mathcal{F}_s] \\
                &= \E[B_t - B_s] + B_s \\
                &= B_s.
            \end{align*}

            \item For $s < t$, by $(1)$,
            \begin{align*}
                \E[Y_t \mid \mathcal{F}_s] &= \E\bj{B_t^2 \mid \mathcal{F}_s}  - t \\
                &= \E\bj{(B_t - B_s)^2 \mid \mathcal{F}_s} +2 \E\bj{B_tB_s \mid \mathcal{F}_s} - \E\bj{B_s^2 \mid \mathcal{F}_s} - t \\
                &= \E\bj{(B_t - B_s)^2} + 2B_s \E[B_t \mid \mathcal{F}_s] - B_s^2 - t  \\
                &= t-s + 2B_s^2 - B_s^2 - t \\
                &= B_s^2 - s = Y_s. 
            \end{align*}

            \item For any $s < t$,
            \begin{align*}
                \E[Z_t \mid \mathcal{F}_s] &= \exp\bc{-\frac{1}{2}\theta^2 t}\E\bj{\exp (\theta B_t - \theta B_s) \exp(\theta B_s) \mid \mathcal{F}_s} \\
                &= \exp\bc{\theta B_s-\frac{1}{2}\theta^2 t}\E\bj{\exp (\theta B_t - \theta B_s) \mid \mathcal{F}_s} \\
                &= \exp\bc{\theta B_s-\frac{1}{2}\theta^2 t}\E\bj{\exp (\theta (B_t - B_s))}.
            \end{align*}
            Because $B_t - B_s \sim \mathcal{N}(0,t-s)$,
            \begin{equation*}
                \E\bj{\exp (\theta (B_t - B_s))} = \frac{1}{\sqrt{2\pi(t-s)}}\int \exp(\theta x)\exp(-\frac{1}{2(t-s)}x^2) dx = \exp\bc{\frac{1}{2}\theta^2(t-s)}.
            \end{equation*}
            So
            \begin{equation*}
                \E[Z_t \mid \mathcal{F}_s] = \exp\bc{\theta B_s-\frac{1}{2}\theta^2 t}\exp\bc{\frac{1}{2}\theta^2(t-s)} = Z_s. \qedhere
            \end{equation*}
        \end{enumerate}
    \end{proof}
\end{exam}

\begin{exam}
    Let $(N_t)_{t \geq 0}$ be a Poisson process with parameter $\lambda$ and $(\mathcal{F}_t)_{t \geq 0}$ be the nature filtration.
    \begin{enumerate}[label=(\arabic{*})]
        \item $(N_t - \lambda t)$ is a martingale.
        \item Let
        \begin{equation*}
            Z_t = (N_t - \lambda t)^2 - \lambda t.
        \end{equation*}
        Then $(Z_t)_{t \geq 0}$ is also a martingale.
        \item Given $\alpha > 0$, set $\beta$ such that
        \begin{equation*}
            L_t = \exp (\alpha N_t - \beta t)
        \end{equation*}
        is a martingale.
    \end{enumerate}
    \begin{proof}
        \begin{enumerate}[label=(\arabic{*})]
            \item For $s < t$,
            \begin{align*}
                \E\bj{ N_t - \lambda t \mid \mathcal{F}_s} & = \E\bj{ N_t - N_s \mid \mathcal{F}_s} + \E\bj{N_s \mid \mathcal{F}_s} -\lambda t \\
                &= \E[N_t - N_s] + N_s - \lambda t\\
                &= \lambda (t - s) + N_s - \lambda t = N_s - \lambda s.
            \end{align*}

            \item For $s < t$,
            \begin{align*}
                \E\bj{Z_t \mid \mathcal{F}_s} & = \E\bj{(N_t - \lambda t)^2 \mid \mathcal{F}_s} - \lambda t\\
                &= \E\bj{N_t^2 \mid \mathcal{F}_s} - 2\lambda t \E\bj{N_t \mid \mathcal{F}_s} + (\lambda t)^2 -  \lambda t \\
                &= \E\bj{(N_t - N_s)^2 \mid \mathcal{F}_s} + 2N_s \E[N_t \mid \mathcal{F}_s] - \E[N_s^2 \mid \mathcal{F}_s] \\
                &\quad  - 2\lambda t \E\bj{N_t - \lambda t \mid \mathcal{F}_s} -(\lambda t)^2 - \lambda t \\
                &= \E\bj{(N_t - N_s)^2} + 2N_s \E[N_t - N_s \mid \mathcal{F}_s] + N_s^2 \\
                &\quad -2\lambda t (N_s - \lambda s) - (\lambda t)^2 - \lambda t \\
                &= \lambda (t-s) + \lambda^2(t-s)^2 + 2\lambda (t-s) N_s + N_s^2 \\
                &\quad - 2\lambda t (N_s - \lambda s) - (\lambda t)^2 - \lambda t \\
                &= (N_s - \lambda s)^2 - \lambda s.
            \end{align*}

            \item For $s < t$,
            \begin{align*}
                \E\bj{L_t \mid \mathcal{F}_s} &= \exp (- \beta t)\E\bj{\exp (\alpha N_t) \mid \mathcal{F}_s} \\
                &= \exp (- \beta t)\E\bj{\exp (\alpha (N_t-N_s))\exp(\alpha N_s) \mid \mathcal{F}_s} \\
                &= \exp (\alpha N_s - \beta t) \E\bj{\exp (\alpha (N_t-N_s))} \\
                &= \exp (\alpha N_s - \beta t) \exp \bc{\lambda(t-s)(e^\alpha - 1)}.
            \end{align*}
            because $N_t - N_s \sim \text{Pois}(\lambda(t-s))$. So when $\beta = \lambda(e^\alpha - 1)$,
            \begin{equation*}
                \E\bj{L_t \mid \mathcal{F}_s} = \exp (\alpha N_s - \beta s) = L_s. \qedhere
            \end{equation*}
        \end{enumerate}
    \end{proof}
\end{exam}

\begin{prop}
    Let $f \colon \R \sto \R$ be convex function.
    \begin{enumerate}[label=(\arabic{*})]
        \item If $X = (X_t)_{t \geq 0}$ is a martingale and $f(X_t) \in L^1$, then $\bb{f(X)_t}_{t\geq 0}$ is a submartingale.
        \item If $X = (X_t)_{t \geq 0}$ is a submartingale and $f$ is increasing and $f(X_t) \in L^1$, then $\bb{f(X)_t}_{t\geq 0}$ is a submartingale.
    \end{enumerate}
\end{prop}
\begin{rmk}
    In general, we take $f(x) = \abs{x}^p$ with $p \geq 1$ and $f(x) = x^+$.
\end{rmk}

\begin{thm}
    Let $X = (X_t)_{t \geq 0}$ be a sub(super)martingale. Then
    \begin{equation*}
        \sup_{s \in [0,t]} \E[\abs{X_s}] < \infty.
    \end{equation*}
\end{thm}
\begin{rmk}
    Note that if $X$ is a martingale, by above $\abs{X_t}$ is a submartingale so
    \begin{equation*}
        \E\bj{\abs{X_s}} \leq  \E\bj{\E\bj{\abs{X_t} \mid \mathcal{F}_s}} \leq \E[\abs{X_t}] < \infty
    \end{equation*}
\end{rmk}
\begin{proof}
    Assume $X$ is a submartingale. So $(X_t^+)_{t \geq 0}$ is also a submartingale. So
    \begin{equation*}
        \E[X_s^+] \leq \E[X_t^+] < \infty.
    \end{equation*}
    On the other hand,
    \begin{equation*}
        \E[X_s^-] = \E[X_s^+] - \E[X_s] \leq \E[X_t^+] - \E[X_0] < \infty.
    \end{equation*}
    So $\sup_{s \in [0,t]}\E[\abs{X_s}] = \sup_{s \in [0,t]} \E[X_s^+] + \E[X_s^-] \leq 2\E[X_t^+] - \E[X_0] < \infty$.
\end{proof}


\begin{thm}
    Let $X=(X_t)_{t \geq 0}$ be a positive submartingale (or martingale) with right-continuous paths.
    \begin{enumerate}[label=(\arabic{*})]
        \item Maximum inequality: For any $\lambda > 0$,
        \begin{equation*}
            \Pb\bc{\sup_{s \in [0,t]} \abs{X_s} > \lambda} \leq \frac{1}{\lambda} \E[\abs{X_t}].
        \end{equation*}

        \item Doob's inequality: For any $p > 1$ and $t > 0$,
        \begin{equation*}
            \E\bj{\sup_{s \in [0,t]} \abs{X_s}^p} \leq \bc{\frac{p}{1 - p}}^p \E\bj{\abs{X_t}^p}.
        \end{equation*}
    \end{enumerate}
\end{thm}
\begin{proof}
    Fix $t > 0$. Consider a countable dense subset $D \subset [0,t]$ containing $0$ and $t$. Let $D_m = \bb{0 = t_0^m < t_1^m < \cdots < t^m_m = t}$ such that $D_m \uparrow D$. By the continuity of path
    \begin{equation*}
        \Pb\bc{\sup_{s \in [0,t]} \abs{X_s} > \lambda} = \Pb\bc{\sup_{s \in D} \abs{X_s} > \lambda},\quad \E\bj{\sup_{s \in [0,t]} \abs{X_s}^p} = \E\bj{\sup_{s \in D} \abs{X_s}^p}.
    \end{equation*}
    And by the convergence,
    \begin{equation*}
        \Pb\bc{\sup_{s \in D} \abs{X_s} > \lambda} = \lim_{m \sto \infty } \Pb\bc{\sup_{s \in D_m} \abs{X_s} > \lambda},\quad  \E\bj{\sup_{s \in D} \abs{X_s}^p} = \lim_{m \sto \infty } \E\bj{\sup_{s \in D_m} \abs{X_s}^p}.
    \end{equation*}
    When $X=(X_t)_{t \geq 0}$ be a positive submartingale (or martingale), $(\abs{X_{t_n^m}})$ is also a submartingale. Then by the discrete case, we have the inequalities.
\end{proof}
\begin{rmk}
    If $X$ is a nonnegative supermartingale with right-continuous paths, by the proof of discrete case, we clearly have
    \begin{equation*}
        \Pb\bc{\sup_{s \in [0,t]} X_s > \lambda} \leq \frac{1}{\lambda}\E[X_0].
    \end{equation*}
    Moreover, if $X$ is a supermartingale with right-continuous paths, 
    \begin{equation*}
        \Pb\bc{\sup_{s \in [0,t]} \abs{X_s} > \lambda} \leq \frac{1}{\lambda} (\E[\abs{X_0}]+2\E[\abs{X_t}]).
    \end{equation*}
    \begin{proof}
        By above, we only need to prove the discrete case for a supermartingale $(X_n)_{n \geq 0}$. First, let $N = \min \bb{ n\colon X_n > \lambda } \wedge k$. Then by the optional stopping time theorem,
        \begin{align*}
            \E[X_0] &\geq \E\bj{X_N} = \E\bj{X_N\mathbb{I}_{\bb{\max_{0 \leq n \leq k} X_n > \lambda}}} + \E\bj{X_N\mathbb{I}_{\bb{\max_{0 \leq n \leq k} X_n \leq \lambda}}} \\
            &\geq \lambda \Pb\bc{\max_{0 \leq n \leq k} X_n > \lambda} + \E\bj{X_k\mathbb{I}_{\bb{\max_{0 \leq n \leq k} X_n \leq \lambda}}} \\
            &\geq \lambda \Pb\bc{\max_{0 \leq n \leq k} X_n > \lambda} - \E\bj{\abs{X_k}}.
        \end{align*}
        So we have
        \begin{equation*}
            \lambda \Pb\bc{\max_{0 \leq n \leq k} X_n > \lambda} \leq \E[X_0] + \E\bj{\abs{X_k}}.
        \end{equation*}
        On the other hand, let $T = \min \bb{n \colon X_n \leq -\lambda} \wedge k$. Then
        \begin{align*}
            \E[X_k]&\leq \E\bj{X_T} = \E\bj{X_T\mathbb{I}_{\bb{\max_{0 \leq n \leq k} X_n < - \lambda}}} + \E\bj{X_T\mathbb{I}_{\bb{\max_{0 \leq n \leq k} X_n \geq -\lambda}}} \\
            &\leq -\lambda \Pb\bc{\max_{0 \leq n \leq k} X_n < - \lambda} + \E\bj{X_k\mathbb{I}_{\bb{\max_{0 \leq n \leq k} X_n \geq -\lambda}}} 
        \end{align*}
        So
        \begin{align*}
            \lambda \Pb\bc{\max_{0 \leq n \leq k} X_n < - \lambda} &\leq -\bc{\E[X_k] - \E\bj{X_k\mathbb{I}_{\bb{\max_{0 \leq n \leq k} X_n \geq -\lambda}}} } \\
            &= \E\bj{-X_k\mathbb{I}_{\bb{\max_{0 \leq n \leq k} X_n < -\lambda}}}\\
            &\leq \E\bj{\abs{X_k}}.
        \end{align*}
        Therefore, we have
        \begin{equation*}
            \lambda \Pb\bc{\max_{0 \leq n \leq k} \abs{X_n} > \lambda} \leq 2\E\bj{\abs{X_k}} + \E\bj{\abs{X_0}}. \qedhere
        \end{equation*}
    \end{proof}
\end{rmk}

\section{Path Regularity}

\begin{defn}
    Let $f \colon I \sto \R$ with $I \subset \R_+$. For $a < b$, define
    \begin{equation*}
        M_{a, b}^f(I) \stackrel{\text { def }}{=} \sup \left\{k \in \mathbb{N}_{+}: \exists\left\{s_1<t_1<s_2<t_2<\cdots<s_k<t_k\right\} \subset I \text { s.t. } f\left(s_i\right) \leqslant a, f\left(t_i\right) \geqslant b, \forall i \in[k]\right\}
    \end{equation*}
    be the number of up-crossing of $f$ on $(a,b)$.
\end{defn}

\begin{lem}
    Let $D \subset \R_+$ be a countable dense subset of $\R_+$ and $f \colon D \sto \R$. Assume that for any $T \in D$,
    \begin{enumerate}[label=(\roman*)]
        \item $f$ is bounded on $D \cap [0,T]$,
        \item $M_{a,b}^f(D) < \infty$ for any $a,b \in \Q$ with $a < b$.
    \end{enumerate}
    Then
    \begin{enumerate}[label=(\arabic{*})]
        \item for any $t \geq 0$,
        \begin{equation*}
            \lim_{s \downarrow t,s\in D}f(s) \eqdef f(t+)
        \end{equation*}
        exits.
        \item for any $t > 0$,
        \begin{equation*}
            \lim_{s \uparrow t,s\in D}f(s) \eqdef f(t-)
        \end{equation*}
        exits.
    \end{enumerate}
    Furthermore, define $g(t) = f(t+)$ then $g$ is c\`adl\`ag (or RLCC), i.e. right-continuous with left-limit.
\end{lem}
\begin{proof}
    Assume for $t > 0$,
    \begin{equation*}
        \lim_{s \downarrow t,s\in D}f(s)
    \end{equation*}
    does not exists. Then by the boundedness of $f$, 
    \begin{equation*}
        \liminf_{s \downarrow t,s\in D}f(s) <\limsup_{s \downarrow t,s\in D}f(s),
    \end{equation*}
    which implies that there exist $a,b \in \Q$ such that
    \begin{equation*}
        \liminf_{s \downarrow t,s\in D}f(s)< a < b <\limsup_{s \downarrow t,s\in D}f(s).
    \end{equation*}
    It follows that
    \begin{equation*}
        M_{a,b}^f(D) = \infty. \qedhere
    \end{equation*}
\end{proof}

\begin{thm}
    Let $X = (X_t)_{t \geq 0}$ be a supermartingale and $D$ be a countable dense subset of $\R_+$. Then
    \begin{enumerate}[label=(\arabic{*})]
        \item for a.e. $\omega \in \Omega$,
        \begin{equation*}
            X_{t+}(\omega) \defeq \lim_{s \downarrow t,s\in D} X_s(\omega),\quad X_{t-}(\omega) \defeq \lim_{s \uparrow t,s\in D} X_s(\omega)
        \end{equation*}
        exist.
        \item for every $t \in \R_+$, $X_{t+} \in L^1$ and 
        \begin{equation*}
            X_t \geq \E\bj{X_{t+} \mid \mathcal{F}_t},
        \end{equation*}
        where ``$=$'' if and only if $t \mapsto \E[X_t]$ is right-continuous.
        \item $(X_{t+})_{t \geq 0}$ is a supermartingale w.s.t. $(\mathcal{F}_{t+})_{t \geq 0}$. Moreover, it is a martingale if $X$ is a martingale.
    \end{enumerate}
\end{thm}
\begin{proof}
    \begin{enumerate}[label=(\arabic{*})]
        \item First, give any $T>0$ and $\lambda > 0$, we have
        \begin{equation*}
            \Pb\bc{\sup_{t \in [0,T]} \abs{X_t} > \lambda} \leq \frac{1}{\lambda} \bc{\E[\abs{X_0}] + 2\E\bj{\abs{X_T}}}.
        \end{equation*}
        As $\lambda \sto \infty$,
        \begin{equation*}
            \Pb\bc{\sup_{t \in [0,T]} \abs{X_t} < \infty} = 1.
        \end{equation*}
        Therefore, $\sup_{t \in [0,T]} \abs{X_t} < \infty$ a.e.. Second, choose a sequence $(D_m)$ of finite subsets of $D$ such that $D_m \uparrow D$ and $T \in D_m$. By the upcrossing inequality of the discrete case of $(X_{s_k}, k \in D_m \cap [0,T])$,
        \begin{equation*}
            \E\bj{M^X_{a,b}(D_m \cap [0,T])} \leq \frac{1}{b-a}\E\bj{(X_T - a)^-}.
        \end{equation*}
        As $m \sto \infty$, by DCT,
        \begin{equation*}
            \E\bj{M^X_{a,b}(D \cap [0,T])} \leq \frac{1}{b-a}\E\bj{(X_T - a)^-} < \infty,
        \end{equation*}
        which implies that $M^X_{a,b}(D \cap [0,T]) < \infty$ a.e.. By choosing the union of such zero measure set, the above lemma implies $X_{t+},X_{t-}$ exist a.e..

        \item First, choose a sequence $(t_n)_{n \in \N} \subset D$ such that $t_n \downarrow t$ and $t_n \leq t+1$, so $X_{t+} = \lim_{n\sto \infty}X_{t_n}$. Note that $(X_{t_n})$ is a backward supermartingale (by let $Y_{-n} = X_{t_n}$) and
        \begin{equation*}
            \sup_n \E[\abs{X_{t_n}}] \leq \sup_{s \in [0,t+1]}\E[\abs{X_t}] < \infty.
        \end{equation*}
        By Martingale Convergence Theorem for discrete case (backward case),
        \begin{equation*}
            \lim_{n \sto \infty} X_{t_n} = X_{t+}
        \end{equation*}
        in $L^1$ and so $X_{t+} \in L^1$. Note that
        \begin{equation*}
            X_t \geq \E\bj{X_{t_n} \mid \mathcal{F}_t}.
        \end{equation*}
        Because $X_{t_n} \sto X_{t+}$ in $L^1$,
        \begin{equation*}
            X_t \geq \E\bj{X_{t+} \mid \mathcal{F}_t}.
        \end{equation*}
        Note that if $X_1 \geq X_2$ and $\E[X_1] = \E[X_2]$, then $X_1=X_2$. Assume $t \mapsto \E[X_t]$ is right-continuous. Then
        \begin{equation*}
            \E[X_t] = \lim_{t_n \sto t} \E[X_{t_n}] = \E[X_{t+}] = \E\bj{\E\bj{X_{t+} \mid \mathcal{F}_t}}.
        \end{equation*}
        It follows that $X_t = \E\bj{X_{t+} \mid \mathcal{F}_t}$. Conversely, it is obvious.

        \item Let $s < t$. Choose $(s_n)_n \subset D$ and $(t_n)_n \subset D$ such that $s_n \downarrow s$ and $t_n \downarrow t$ and $s_n \leq t_n$. Then
        \begin{equation*}
            X_{s_n} \geq \E\bj{X_{t_n} \mid \mathcal{F}_{s_n}},\quad \forall~n.
        \end{equation*}
        Now for any $A \in \mathcal{F}_{s+} = \bigcap_n\mathcal{F}_{s_n}$, we have
        \begin{equation*}
            \E[X_{s_n}\mathbb{I}_A] \geq \E[X_{t_n}\mathbb{I}_A].
        \end{equation*}
        As $n \sto \infty$, by $(2)$,
        \begin{equation*}
            \E[X_{s+}\mathbb{I}_A] \geq \E[X_{t+}\mathbb{I}_A] = \E\bj{\mathbb{I}_A \E[X_{t+} \mid \mathcal{F}_{s+}]}.
        \end{equation*}
        Because $X_{s+}$ and $\E[X_{t+} \mid \mathcal{F}_{s+}]$ are $\mathcal{F}_{s+}$-measurable,
        \begin{equation*}
            X_{s+} \geq \E[X_{t+} \mid \mathcal{F}_{s+}]. \qedhere
        \end{equation*}
    \end{enumerate}
\end{proof}

\begin{thm}[Regularizing Path]
    Assume $(\mathcal{F}_t)_{t\geq 0}$ is right-continuous and complete. Let $X=(X_t)_{t\geq 0}$ be a supermartingale such that $t \mapsto \E[X_t]$ is right-continuous. Then there is a $(Y_t)_{t \geq 0}$ such that it has c\`adl\`ag path and it is a supermartingale and $Y_t = X_t$ a.e. (called a modification of $X$).
\end{thm}
\begin{proof}
    Let $Y_t = X_{t+}$. Then it is a supermartingale w.s.t. $(\mathcal{F}_{t+})_{t\geq 0} = (\mathcal{F}_t)_{t\geq 0}$, which has c\`adl\`ag path. Moreover, by the right-continuity of $t \mapsto \E[X_t]$,
    \begin{equation*}
        X_t = \E[X_{t+} \mid \mathcal{F}_t] = \E[Y_t \mid \mathcal{F}_t] = Y_t. \qedhere
    \end{equation*}
\end{proof}

\section{Convergence Theorem}

\begin{thm}[Martingale Convergence Theorem]
    Let $X = (X_t)_{t \geq 0}$ be a supermartingale with right-continuous paths such that
    \begin{equation*}
        \sup_t \E[\abs{X_t}] < \infty
    \end{equation*}
    Then there exists a $X_\infty \in L^1$ such that
    \begin{equation*}
        \lim_{t \sto \infty} X_t = X_\infty
    \end{equation*}
    a.e..
\end{thm}
\begin{proof}
    Let $D$ be a countable and dense subset of $\R_+$. For any $T \in D$ and $a < b$, 
    \begin{equation*}
        \E\bj{M_{a,b}^X(D \cap [0,T])} \leq \frac{1}{b-a}\E[(X_T - a)^-].
    \end{equation*}
    So
    \begin{equation*}
        \E\bj{M_{a,b}^X(D \cap [0,T])} \leq \frac{1}{b-a}\sup_T\E[(X_T - a)^-]  = M <\infty.
    \end{equation*}
    As $T \sto \infty$, by MCT,
    \begin{equation*}
        \E\bj{M_{a,b}^X(D)} \leq M < \infty\quad \Rightarrow \quad M_{a,b}^X(D) < \infty,~\forall~a,b
    \end{equation*}
    Therefore, by above lemma,
    \begin{equation*}
        X_\infty = \lim_{ D \ni t \sto \infty} X_t.
    \end{equation*}
    By Fatou's lemma,
    \begin{equation*}
        \E\bj{\abs{X_\infty}} \leq \liminf_{D \ni t \sto \infty}\E\bj{\abs{X_t}} \leq \sup_t \E[\abs{X_t}] < \infty.
    \end{equation*}
    Therefore, for any $\varphi > 0$, there exists $N$ such that for all $D \ni t \geq N$,
    \begin{equation*}
        \abs{X_t - X_\infty} < \varepsilon.
    \end{equation*}
    Then for any $s \geq N$, let $s_n \downarrow s$ in $D$, so
    \begin{equation*}
        \abs{X_{s_n} - X_\infty} < \varepsilon.
    \end{equation*}
    As $n \sto \infty$, because $(X_t)$ is right-continuous,
    \begin{equation*}
        \abs{X_s - X_\infty} < \varepsilon,
    \end{equation*}
    which implies that
    \begin{equation*}
        X_\infty = \lim_{t \sto \infty} X_t. \qedhere
    \end{equation*}
\end{proof}

\begin{defn}[Closedness]
    A martingale $X=(X_t)_{t\geq 0}$ is called closed if there exists a $Z \in L^1$ such that
    \begin{equation*}
        X_t = \E[Z \mid \mathcal{F}_t],\quad \forall~ t \geq 0.
    \end{equation*}
\end{defn}

\begin{thm}
    Let $X = (X_t)_{t \geq 0}$ be a martingale with RLCC path. TFAE.
    \begin{enumerate}[label=(\arabic{*})]
        \item $X$ is closed.
        \item $X$ is UI.
        \item $X_t$ converges a.e. and in $L^1$.
    \end{enumerate}
    Moreover, in such cases, $X_t = \E[X_\infty \mid \mathcal{F}_t]$ for $X_\infty = \lim_t X_t$.
\end{thm}
\begin{proof}
    $(1) ~\Rightarrow~ (2)$: It has been proved in above chapter.

    \noindent $(2) ~\Rightarrow~ (3)$: Because $X$ is UI,
    \begin{equation*}
        \sup_t \E[\abs{X_t}] < \infty.
    \end{equation*}
    Then by above theorem,
    \begin{equation*}
        \lim_{t \sto \infty} X_t = X_\infty
    \end{equation*}
    a.e..  Then because of UI, it is in $L^1$.

    \noindent $(3)~\Rightarrow~(1)$: For $t < T$,
    \begin{equation*}
        X_t = \E[X_T \mid \mathcal{F}_t].
    \end{equation*}
    As $T \sto \infty$, because $X_\infty = \lim_t X_t$ in $L^1$,
    \begin{equation*}
        X_t = \E\bj{X_\infty \mid \mathcal{F}_t}. \qedhere
    \end{equation*}
\end{proof}
\begin{rmk}
    In such case, for any stopping time $T$, we can define
    \begin{equation*}
        X_T(\omega) \defeq \mathbb{I}_{T(\omega) < \infty} X_{T(\omega)}(\omega) + \mathbb{I}_{T(\omega) = \infty}X_\infty(\omega).
    \end{equation*}
\end{rmk}

\section{Optional Stopping Time}

\begin{thm}
    Let $(Y_n)_{n \geq 0}$ be a discrete UI martingale. Then for any stopping times $M \leq N$,
    \begin{equation*}
        Y_M = \E[Y_N \mid \mathcal{F}_M].
    \end{equation*}
    In particular, when $M,N$ are bounded, no UI is required.
\end{thm}
\begin{proof}
    First, $Y_M \in L^1$ is by $(Y_{n \wedge M})$ is a UI martingale and $Y_{n \wedge M} \sto Y_M$ (If $M,N$ bounded, $Y_N = \sum_k\mathbb{I}_{\bb{N=k}} Y_k \in L^1$). We already know $Y_M$ is $\mathcal{F}_M$ measurable. For any $A \in \mathcal{F}_M \subset \mathcal{F}_N$, consider
    \begin{equation*}
        M^A = \begin{cases}
            M,&\omega \in A \\
            \infty,& \omega \in A^c
        \end{cases},\quad N^A = \begin{cases}
            N,&\omega \in A \\
            \infty,& \omega \in A^c,
        \end{cases}
    \end{equation*}
    and they are stopping times because $A \in \mathcal{F}_M,\mathcal{F}_N$. $M^A \leq N^A$. Moreover, by optional stopping time theorem
    \begin{equation*}
        \E[Y_0] = \E\bj{Y_{M^A}} = \E\bj{Y_{N^A}}.
    \end{equation*}
    Note that
    \begin{equation*}
        \E\bj{Y_{M^A}} = \E[Y_M\mathbb{I}_A] + \E[Y_\infty \mathbb{I}_{A^c}],\quad\E\bj{Y_{N^A}} = \E[Y_N\mathbb{I}_A] + \E[Y_\infty \mathbb{I}_{A^c}]. 
    \end{equation*}
    So
    \begin{equation*}
        \E[Y_M\mathbb{I}_A] = \E[Y_N\mathbb{I}_A].
    \end{equation*}
    It follows that
    \begin{equation*}
        Y_M = \E[Y_N \mid \mathcal{F}_M]. \qedhere
    \end{equation*}
\end{proof}
\begin{rmk}
    For super(sub)martingale, it has similar result.  Let $(Z_n)_{n \geq 0}$ be a discrete UI supermartingale. Then for any stopping times $S \leq T$,
    \begin{equation*}
        \E[Z_T \mid \mathcal{F}_S] \leq Z_S
    \end{equation*}
    In particular, when $S,T \leq m$ are bounded, no UI is required. First, $Z_S,Z_T \in L^1$ as same as above. Let $A \in \mathcal{F}_S$. Note that $\bb{Z_{T \wedge n}}_{n \geq 0}$ is still a supermartingale. First, $A \cap \bb{S = k} \in \mathcal{F}_k$. So
    \begin{align*}
        \E[Z_T \mathbb{I}_A] &= \E[Z_{T\wedge m} \mathbb{I}_A] \\
        &= \sum_{k=0}^m \E\bj{\mathbb{I}_{A \cap \bb{S = k}} Z_{T \wedge m}} \\
        &= \sum_{k=0}^m \E\bj{\mathbb{I}_{A \cap \bb{S = k}} \E\bj{Z_{T \wedge m} \mid \mathcal{F}_k}}\\
        &\leq \sum_{k=0}^m \E\bj{\mathbb{I}_{A \cap \bb{S = k}} Z_{T \wedge k}} \\
        &= \sum_{k=0}^m \E\bj{\mathbb{I}_{A \cap \bb{S = k}} Z_{T \wedge S}} \\
        &= \sum_{k=0}^m \E\bj{\mathbb{I}_{A \cap \bb{S = k}} Z_{S}} \\
        &= \E\bj{\mathbb{I}_A Z_S}.
    \end{align*}
\end{rmk}


\begin{thm}[Doob's Optional Stopping Time]
    Let $X=(X_t)_{t \geq 0}$ be a UI martingale with right-continuous paths. Let $S$ and $T$ be two stopping times with $S \leq T$. Then $X_S,X_T \in L^1$ and
    \begin{equation*}
        X_S= \E[X_T \mid \mathcal{F}_S].
    \end{equation*}
\end{thm}
\begin{proof}
    First, it is obvious $X_S$ is $L^1$ and $\mathcal{F}_S$ measurable. Set for any integer $n > 0$,
    \begin{equation*}
        T_n = \sum_{k=0}^\infty \frac{k+1}{2^n}\mathbb{I}_{\frac{k}{2^n} < T \leq \frac{k+1}{2^n}} + \infty \mathbb{I}_{T = \infty},
    \end{equation*}
    and
    \begin{equation*}
        S_n = \sum_{k=0}^\infty \frac{k+1}{2^n}\mathbb{I}_{\frac{k}{2^n} < S \leq \frac{k+1}{2^n}} + \infty \mathbb{I}_{S = \infty}.
    \end{equation*}
    Note that $T_n$ and $S_n$ are stopping times with $T_n \downarrow T$ and $S_n \downarrow S$ and $S_n \leq T_n$. Since $(X_{\frac{k}{2^n}})_{k \geq 0}$ is a UI martingale, by above theorem,
    \begin{equation*}
        X_{S_n} = \E[X_{T_n} \mid \mathcal{F}_{S_n}].
    \end{equation*}
    Let $A \in \mathcal{F}_S$. Because $\mathcal{F}_{S} \subset \mathcal{F}_{S_n}$,
    \begin{equation*}
        \E[\mathbb{I}_A X_{S_n}] = \E[\mathbb{I}_A X_{T_n}].
    \end{equation*}
    Let $n \sto \infty$. By the right-continuity of path and UI,
    \begin{equation*}
        \E[\mathbb{I}_A X_{S}] = \E[\mathbb{I}_A X_{T}]. \qedhere
    \end{equation*}
\end{proof}

\begin{cor}[Bounded Optional Stopping Time]
    Let $X = (X_t)_{t \geq 0}$ be a martingale with right-continuous paths. Let $S \leq T$ be two bounded stopping times. Then $X_S,X_T \in L^1$ and
    \begin{equation*}
        X_S = \E[X_T \mid \mathcal{F}_S].
    \end{equation*}
\end{cor}
\begin{proof}
    Assume $S \leq T \leq a$ for some constant $a$. Consider the martingale $Y_t = X_{t \wedge a}$. Then because $Y_t = \E[X_a \mid \mathcal{F}_t]$, $(Y_t)$ is UI. So
    \begin{equation*}
        Y_S = X_{S \wedge a} = X_S,\quad Y_T = X_{T \wedge a} = X_T \in L^1,
    \end{equation*}
    and $X_S = \E[X_T \mid \mathcal{F}_S]$.
\end{proof}

\begin{cor}
    Let $X = (X_t)_{t \geq 0}$ be a martingale with right-continuous paths. Let $T$ be a stopping time. Then
    \begin{enumerate}[label=(\arabic{*})]
        \item the process $(X_{t \wedge T})_{t \geq 0}$ is also a martingale.
        \item if $X$ is UI, then $(X_{t \wedge T})_{t \geq 0}$ is UI and
        \begin{equation*}
            X_{t \wedge T} = \E[X_T \mid \mathcal{F}_t].
        \end{equation*}
    \end{enumerate}
\end{cor}
\begin{proof}
    For $(2)$, note $t \wedge T$ is also a stopping time with $t \wedge T \leq T$ and $X_{t \wedge T}$ is $\mathcal{F}_{t \wedge T}$-measurable and sp $\mathcal{F}_t$-measurable. For any $A \in \mathcal{F}_t$, let
    \begin{equation*}
        A = (A \cap \bb{T \leq t}) \cup (A \cap \bb{T > t}).
    \end{equation*}
    Then
    \begin{align*}
        \E[X_{t \wedge T} \mathbb{I}_A] &= \E[X_{t \wedge T} \mathbb{I}_{A \cap \bb{T \leq t}}] + \E[X_{t \wedge T} \mathbb{I}_{A \cap \bb{T > t}}],\\
        &= \E[X_{T} \mathbb{I}_{A \cap \bb{T \leq t}}] + \E[X_{t \wedge T} \mathbb{I}_{A \cap \bb{T > t}}],\\
        \E[X_{T} \mathbb{I}_A] &= \E[X_{T} \mathbb{I}_{A \cap \bb{T \leq t}}] + \E[X_{T} \mathbb{I}_{A \cap \bb{T > t}}],
    \end{align*}
    so to prove $\E[X_{t \wedge T} \mathbb{I}_A] = \E[X_{T} \mathbb{I}_A]$, it suffices to show
    \begin{equation*}
        \E[X_{t \wedge T} \mathbb{I}_{A \cap \bb{T > t}}] = \E[X_{T} \mathbb{I}_{A \cap \bb{T > t}}].
    \end{equation*}
    Because $X$ is UI, by above
    \begin{equation*}
        X_{t \wedge T} = \E[X_T \mid \mathcal{F}_{t \wedge T}].
    \end{equation*}
    So we only need to show $A \cap \bb{T > t} \in \mathcal{F}_{t \wedge T}$.
    \begin{equation*}
        (A \cap \bb{T > t}) \cap \bb{t \wedge T \leq s} = A \cap \bb{T > t} \cap \bb{t \leq s} \in \mathcal{F}_t \subset \mathcal{F}_s
    \end{equation*}
    It follows
    \begin{equation*}
        X_{t \wedge T} = \E[X_T \mid \mathcal{F}_t].
    \end{equation*}
    And $X_T \in L^1$ by above theorem, so $(X_{t \wedge T})_{t \geq 0}$ is UI.

    \noindent For $(1)$, let $a > 0$ and consider $(X_{t \wedge a})_{t \geq 0}$ that is obvious a UI martingale. So by $(2)$,
    \begin{equation*}
        X_{t \wedge a \wedge T} = X_{t \wedge T}
    \end{equation*}
    is a martingale for any $t \geq a$.
\end{proof}
\begin{rmk}
    In fact, if $X = (X_t)_{t \geq 0}$ be a submartingale with right-continuous paths, then $(X_{t \wedge T})_{t \geq 0}$ is also a submartingale for any stopping time $T$ by discretization. Moreover, by the same reasoning as the discrete case, if $X = (X_t)_{t \geq 0}$ is a UI submartingale, so is $(X_{t \wedge T})_{t \geq 0}$.
\end{rmk}

\begin{exam}
    Let $(B_t)_{t \geq 0}$ be a standard Brownian motion. Let $a \in \R$ and define
    \begin{equation*}
        T_a = \inf\bb{t \geq 0\colon B_t = a}.
    \end{equation*}
    Assume $a < 0 < b$. Define $T = T_a \wedge T_b$.
    \begin{enumerate}[label=(\arabic{*})]
        \item Determine the following probability: $\Pb(T_a < T_b)$ and $\Pb(T_b \leq T_a)$.
        \item Find $\E[T]$.
        \item For $\lambda > 0$, find $\E\bj{e^{-\lambda T_a}}$.
    \end{enumerate}
    \noindent \emph{Solution:} 
    \begin{enumerate}[label=(\arabic{*})]
        \item Because $N_t = B_{t \wedge T}$ is a martingale and bounded by $\abs{a}+b$, it is UI. So by optional stopping time theorem,
        \begin{equation*}
            \E\bj{N_T} = \E\bj{B_T} = \E[N_0] = 0
        \end{equation*}
        On the other hand,
        \begin{equation*}
            \E[B_T] = a\Pb(T_a < T_b) + b \Pb(T_b \leq T_a) = 0
        \end{equation*}
        So
        \begin{equation*}
            \Pb(T_a < T_b) = \frac{b}{b-a},\quad \Pb(T_b \leq T_a) = \frac{-a}{b-a}.
        \end{equation*}

        \item We already know $M_t = B_t^2 - t$ is a martingale. So $M_{t \wedge T} = B^2_{t\wedge T} - t \wedge T$ is also a martingale. 
        \begin{equation*}
            \E[M_{t \wedge T}] = 0~\Rightarrow~ \E\bj{B^2_{t\wedge T}} = \E\bj{t \wedge T}.
        \end{equation*}
        As $t \sto \infty$, by the DCT on the LHS and the MCT on the RHS,
        \begin{equation*}
            \E[T] = \E\bj{B_T^2} = -ab.
        \end{equation*}

        \item Fix a $b\in \R$. Consider the martingale
        \begin{equation*}
            N^b_t = \exp \bc{bB_t - \frac{1}{2}b^2 t}.
        \end{equation*}
        Assume $b > 0$. Note that $(N^b_{t \wedge T_a})_{t \geq 0}$ is also a martingale. Moreover, because
        \begin{equation*}
            \abs{N^b_{t \wedge T_a}} = \exp\bc{bB_{t \wedge T_a} - \frac{1}{2}b^2 t \wedge T_a} \leq \exp\bc{bB_{t \wedge T_a}} \leq \exp(b\abs{a}),
        \end{equation*}
        $Y_t = N^b_{t \wedge T_a}$ is UI. So by the optional stopping theorem,
        \begin{equation*}
            \E[Y_{\infty}] = \E\bj{N^b_{T_a}} = \E[Y_0] = 1.
        \end{equation*}
        On the other hand,
        \begin{equation*}
            \E\bj{N^b_{T_a}} = \E\bj{\exp\bc{bB_{T_a} - \frac{1}{2}b^2 T_a}} = \E\bj{\exp\bc{ba - \frac{1}{2}b^2 T_a}} = \exp(ab)\E\bj{e^{-\frac{1}{2}b^2T_a}}.
        \end{equation*}
        So let $b = \sqrt{2\lambda}$.
        \begin{equation*}
            \E\bj{e^{-\lambda T_a}} = e^{-\sqrt{2\lambda}a}.
        \end{equation*}
    \end{enumerate}
\end{exam}

\begin{thm}
    Assume $Z = (Z_t)_{t \geq 0}$ is a nonnegative supermartingale with right-continuous paths. Let $U,V$ be stopping times with $U \leq V$. Then $Z_U,Z_V \in L^1$ and 
    \begin{equation*}
        Z_U \geq \E\bj{Z_V \mid \mathcal{F}_U}.
    \end{equation*}
\end{thm}
\begin{proof}
    \begin{enumerate}[label=(\roman*)]
        \item First, assume $U \leq V \leq P$ for some integer $P$. Let
        \begin{equation*}
            U_n = \sum_{k=0}^\infty \frac{k+1}{2^n}\mathbb{I}_{\bb{\frac{k}{2^n} < U \leq \frac{k+1}{2^n}}},\quad V_n = \sum_{k=0}^\infty \frac{k+1}{2^n}\mathbb{I}_{\bb{\frac{k}{2^n} < V \leq \frac{k+1}{2^n}}}.
        \end{equation*}
        So they are stopping times with $U_n \downarrow U$, $V_n \downarrow V$, and $U_n \leq V_n$. Because of the right-continuity of paths,
        \begin{equation*}
            Z_{U_n} \sto Z_U,\quad Z_{V_n} \sto Z_V.
        \end{equation*}
        Moreover, we can consider $(Y_{k} = Z_{U_{-k}})_{k \leq 0}$. Because $U_{n+1} \leq U_{n}$, by the optional stopping time theorem (bounded case),
        \begin{equation*}
            \E\bj{Z_{U_n} \mid \mathcal{F}_{U_{n+1}}} \leq Z_{U_{n+1}},
        \end{equation*}
        so $(Y_{k})$ is a backward supermartingale with $\E[Y_{k}] \leq \E[Z_0] < \infty$. It follows that $(Y_k)$ is UI and so $Z_{U_n} \sto Z_U$ in $L^1$, so is $ Z_{V_n} \sto Z_V$ in $L^1$.

        \noindent Because $U_n \leq V_n$, by the optional stopping time theorem (bounded case),
        \begin{equation*}
            \E\bj{Z_{V_n} \mid \mathcal{F}_{U_n}} \leq Z_{U_n},
        \end{equation*}
        which implies that
        \begin{equation*}
            \E[Z_{V_n}] \leq Z_{U_n}.
        \end{equation*}
        As $n \sto \infty$, by $L^1$-convergence
        \begin{equation*}
            \E[Z_{V}] \leq \E\bj{Z_{U}}.
        \end{equation*}

        \item Next, consider general $U \leq V$. It is obvious $Z_U$ is $\mathcal{F}_U$-measurable. To prove
        \begin{equation*}
            \E[Z_V \mid \mathcal{F}_U] \leq Z_U,
        \end{equation*}
        it suffices to prove that for any $A \in \mathcal{F}_U$,
        \begin{equation*}
            \E[Z_V \mathbb{I}_A] \leq \E[Z_U\mathbb{I}_A].
        \end{equation*}
        Define
        \begin{equation*}
            U^A = \begin{cases}
                U,& \omega \in A \\
                \infty,&\omega \in A^c
            \end{cases},\quad V^A = \begin{cases}
                V,& \omega \in A \\
                \infty,&\omega \in A^c
            \end{cases}.
        \end{equation*}
        They are stopping times with $U^A \leq V^A$ because $A \in \mathcal{F}_U \subset \mathcal{F}_V$. For any $p \geq 1$, by above step, we have
        \begin{equation*}
            \E\bj{Z_{V^A \wedge p}} \leq \E\bj{Z_{U^A \wedge p}}
        \end{equation*}
        For the RHS,
        \begin{align*}
            \E\bj{Z_{U^A \wedge p}} &= \E\bj{Z_{U^A \wedge p}\mathbb{I}_A} + \E\bj{Z_{U^A \wedge p}\mathbb{I}_{A^c}} \\
            &= \E\bj{Z_{U \wedge p}\mathbb{I}_A} + \E\bj{Z_p\mathbb{I}_{A^c}},
        \end{align*}
        and we have the similar formula for the LHS. So
        \begin{equation*}
            \E\bj{Z_{V \wedge p}\mathbb{I}_A} \leq \E\bj{Z_{U \wedge p}\mathbb{I}_A}
        \end{equation*}
        Note that
        \begin{equation*}
            \mathbb{I}_A = \mathbb{I}_{A\cap \bb{U \leq p}} + \mathbb{I}_{A\cap \bb{U > p}}.
        \end{equation*}
        So
        \begin{equation*}
            \E\bj{Z_{U \wedge p}\mathbb{I}_A} = \E\bj{\mathbb{I}_{A\cap \bb{U \leq p}}Z_U} + \E\bj{\mathbb{I}_{A\cap \bb{U > p}}Z_p}
        \end{equation*}
        and
        \begin{equation*}
            \E\bj{Z_{V \wedge p}\mathbb{I}_A} = \E\bj{\mathbb{I}_{A\cap \bb{U \leq p}}Z_{V \wedge p}} + \E\bj{\mathbb{I}_{A\cap \bb{U > p}}Z_p}.
        \end{equation*}
        It follows that
        \begin{equation*}
            \E\bj{\mathbb{I}_{A\cap \bb{U \leq p}}Z_U} \geq \E\bj{\mathbb{I}_{A\cap \bb{U \leq p}}Z_{V \wedge p}} \geq \E\bj{\mathbb{I}_{A\cap \bb{V \leq p}}Z_{V \wedge p}} 
        \end{equation*}
        because $Z$ is nonnegative. By MCT, as $p \sto \infty$,
        \begin{equation*}
            \E[Z_V \mathbb{I}_A] \leq \E[Z_U\mathbb{I}_A]. \qedhere
        \end{equation*}
    \end{enumerate}
\end{proof}
\begin{rmk}
    Note that if $Z = (Z_t)_{t \geq 0}$ is a UI supermartingale, then above is also clearly true by as $p \sto \infty$ in (\rnum{2}).
\end{rmk}

\begin{prop}
    Let $X=(X_t)_{t \geq 0}$ be a adapted and right-continuous and integrable stochastic process satisfying $X_T \in L^1$ for all bounded stopping time $T$. Then $X$ is a martingale if and only if
    \begin{equation*}
        \E[X_T] = \E[X_0],
    \end{equation*}
\end{prop}
\begin{proof}
    For any $0 \leq s < t$ and any $A \in \mathcal{F}_s$, let
    \begin{equation*}
        T = s \mathbb{I}_{A^c} + t \mathbb{I}_{A}.
    \end{equation*}
    Then $T$ is a bounded stopping time and
    \begin{equation*}
        \E[X_0] = \E[X_T] = \E\bj{X_s \mathbb{I}_{A^c}} + \E\bj{X_t \mathbb{I}_{A}} = \E\bj{X_s}+\E\bj{(X_t - X_s) \mathbb{I}_{A}}.
    \end{equation*}
    Because $\E[X_0] = \E[X_s]$,
    \begin{equation*}
        \E\bj{X_t \mathbb{I}_{A}} = \E\bj{X_s \mathbb{I}_{A}}. 
    \end{equation*}
    So
    \begin{equation*}
        X_s = \E[X_t \mid \mathcal{F}_s]. \qedhere
    \end{equation*}
\end{proof}
\begin{rmk}
    Furthermore, if above conditions are satisfied for all stopping times $T$, then $X$ is UI.
\end{rmk}

